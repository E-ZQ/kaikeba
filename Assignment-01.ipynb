{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2020年1月05日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 作业截止时间\n",
    "此次作业截止时间为 2020.01.12日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：每道题是否回答完整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {Yes. \n",
    "1. The websites make reccommendations according to our habbits.\n",
    "2.The Emaps navigate based on algorithms.\n",
    "3.The robots trained with data deal with after-sales service. }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {We use Github mainly for coorperating, finding and sharing ideas, and Jupyter and Pycharm for coding. Particularly, Jupyter is better for presentiing and Pycharm meets the need of developing.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: We make predictions based on probability theories, like Bayesian models and Markov models. In contrast, while linear regression and linear programming work well in some scenaries, they are not probability models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Predicting whether the bus would arrive on time based on its previous performance, estimating the quality of mass goods by sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Because many times of experiments make the probability approach to the frequency, as law of large numbers tell us, which simplifies the modeling proccedure. However, it is almost impossible to enumerate all of the patterns and parsings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Models that specialize on problems closely related to natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Identifying public focus with cloud map, getting abstracts from articles automaticcally, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: We assume that a sentence is made of a list of words which are independent to each other, and the probability to get the sentence is the multiplication of the probability of each word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: It ignores the order of the words in the sentence and we finally get the chance that all those words occur at a time, similiar to the chance we get the sentence, but different. On the other side, it is simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: In 2-gram models, the occurence of a word is considered to be relevent to the word next to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1569578233461&di=4adfa7597fb380e7cc0e67190bbd7605&imgtype=0&src=http%3A%2F%2Fs1.sinaimg.cn%2Flarge%2F006eYYfyzy76cmpG3Yb1f)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inviting = \"\"\"\n",
    "inviting = 时间 主语 副词 干啥\n",
    "时间 = 今天 | 今儿个 | 今晚 | 明天 | 赶明儿 | 改天\n",
    "主语 = 咱俩 | 咱哥俩 | 我俩 | 哥仨 | 哥儿几个 | 大伙儿\n",
    "副词 = 一块儿 | 去\n",
    "干啥 = 唱唱歌 | 跳跳舞 | 打打牌 | 喝喝酒 | 聊会儿天\n",
    "强邀 = 不去也得去 | 别磨叽 | 是不是哥们儿\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否提出了和课程上区别较大的语法结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "invited = '''\n",
    "invited = 意见 \n",
    "意见 = 同意 ！ | 拒绝 , 原因\n",
    "同意 = 成 | 行 | 就这么定了\n",
    "拒绝 = 不去 | 别介 | 那可不成\n",
    "原因 = 上年纪了 | 孩子大了 | 老丈人要来\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：是否和上一个语法区别比较大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar\n",
    "\n",
    "choice = random.choice\n",
    "\n",
    "def generate(gram, target):\n",
    "    if target not in gram: return target # means target is a terminal expression\n",
    "    \n",
    "    expaned = [generate(gram, t) for t in choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(grammar_str, n):\n",
    "    gram = create_grammar(grammar_str, split = '=')\n",
    "    # gram2 = create_grammar(invited, split = '=')\n",
    "    target1 = 'inviting'\n",
    "    target2 = 'invited'\n",
    "    target3 = '强邀'\n",
    "    for i in range(10):\n",
    "        sen1 = generate(gram, target1)\n",
    "        sen2 = generate(gram, target2)\n",
    "        print(sen1)\n",
    "        print(sen2)\n",
    "        if sen2.find(',') > -1:\n",
    "            sen3 = generate(gram, target3)\n",
    "            print(sen3)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "invitation=\"\"\"\n",
    "inviting = 时间 主语 副词 干啥\n",
    "时间 = 今天 | 今儿个 | 今晚 | 明天 | 赶明儿 | 改天\n",
    "主语 = 咱俩 | 咱哥俩 | 我俩 | 哥仨 | 哥儿几个 | 大伙儿\n",
    "副词 = 一块儿 | 去\n",
    "干啥 = 唱唱歌 | 跳跳舞 | 打打牌 | 喝喝酒 | 聊会儿天\n",
    "强邀 = 不去也得去 | 别磨叽 | 是不是哥们儿\n",
    "invited = 意见 \n",
    "意见 = 同意 ！ | 拒绝 , 原因\n",
    "同意 = 成 | 行 | 就这么定了\n",
    "拒绝 = 不去 | 别介 | 那可不成\n",
    "原因 = 上年纪了 | 孩子大了 | 老丈人要来\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今晚我俩去跳跳舞\n",
      "就这么定了！\n",
      "\n",
      "\n",
      "改天咱俩去跳跳舞\n",
      "不去,上年纪了\n",
      "是不是哥们儿\n",
      "\n",
      "\n",
      "赶明儿大伙儿一块儿唱唱歌\n",
      "成！\n",
      "\n",
      "\n",
      "今儿个咱哥俩去跳跳舞\n",
      "别介,老丈人要来\n",
      "不去也得去\n",
      "\n",
      "\n",
      "改天大伙儿一块儿聊会儿天\n",
      "成！\n",
      "\n",
      "\n",
      "今天哥仨一块儿聊会儿天\n",
      "行！\n",
      "\n",
      "\n",
      "今天咱哥俩一块儿跳跳舞\n",
      "那可不成,孩子大了\n",
      "别磨叽\n",
      "\n",
      "\n",
      "赶明儿我俩一块儿打打牌\n",
      "那可不成,上年纪了\n",
      "别磨叽\n",
      "\n",
      "\n",
      "今天我俩去打打牌\n",
      "行！\n",
      "\n",
      "\n",
      "今天哥仨去聊会儿天\n",
      "就这么定了！\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_n(invitation, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**; 运行代码，观察是否能够生成多个句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点** 1. 是否使用了新的数据集； 2. csv(txt)数据是否正确解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261497\n"
     ]
    }
   ],
   "source": [
    "filename = '/Users/mac/Desktop/movie_comments.csv'\n",
    "content = pd.read_csv(filename)\n",
    "articles = content['comment'].tolist()\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def token(string):\n",
    "    # we will learn the regular expression next course.\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_clean = [''.join(token(str(a)))for a in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mac/Desktop/movie_comments.txt', 'w') as f:\n",
    "    for a in articles_clean:\n",
    "        f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261497\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "source = '/Users/mac/Desktop/movie_comments.txt'\n",
    "for line in (open(source)):\n",
    "    corpus.append(line)\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255221, ['戴', '睡觉', '还', '着', '眼镜'])\n"
     ]
    }
   ],
   "source": [
    "def select_a_sample(corpus):\n",
    "    n=random.randint(0, len(corpus)-1)\n",
    "    sample = cut(corpus[n])\n",
    "    random.shuffle(sample)\n",
    "    return n, sample\n",
    "print(select_a_sample(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = []\n",
    "for i, line in enumerate((open(source))):\n",
    "    # if i % 10000 == 0: print(i)\n",
    "    \n",
    "    # replace 10000 with a big number when you do your homework. \n",
    "    \n",
    "    # if i > 15000: break    \n",
    "    if i != n: \n",
    "        TOKEN += cut(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4490312\n"
     ]
    }
   ],
   "source": [
    "print(len(TOKEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('的电影', 8640), ('看的', 7106), ('都是', 6335), ('让人', 5284), ('的故事', 4709), ('看了', 4585), ('也是', 4408), ('的时候', 4398), ('的人', 4356), ('的是', 4348), ('看完', 3797), ('我的', 3487), ('的片子', 3350), ('让我', 3274), ('这样的', 2852), ('这部电影', 2722), ('很好', 2643), ('电影的', 2551), ('不知道', 2540), ('的感觉', 2502)]\n"
     ]
    }
   ],
   "source": [
    "TOKEN = [str(t) for t in TOKEN]\n",
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]\n",
    "words_count_2 = Counter(TOKEN_2_GRAM)\n",
    "print(words_count_2.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2: return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 改天我俩去跳跳舞 with Prb: 1.1045134938127448e-20\n",
      "sentence: 明天我俩一块儿唱唱歌 with Prb: 7.379313413635661e-27\n",
      "sentence: 赶明儿咱俩一块儿打打牌 with Prb: 1.1045134938127448e-20\n",
      "sentence: 今儿个咱哥俩一块儿聊会儿天 with Prb: 1.2199500580144362e-40\n",
      "sentence: 赶明儿大伙儿一块儿唱唱歌 with Prb: 7.379313413635661e-27\n",
      "sentence: 改天咱俩一块儿打打牌 with Prb: 1.1045134938127448e-20\n",
      "sentence: 今晚咱哥俩一块儿唱唱歌 with Prb: 1.6433861835008408e-33\n",
      "sentence: 今晚咱俩一块儿聊会儿天 with Prb: 5.477953945002803e-34\n",
      "sentence: 今天咱俩去打打牌 with Prb: 1.1045134938127448e-20\n",
      "sentence: 今天咱俩一块儿跳跳舞 with Prb: 1.1045134938127448e-20\n"
     ]
    }
   ],
   "source": [
    "for sen in [generate(create_grammar(inviting), target='inviting') for i in range(10)]:\n",
    "    print('sentence: {} with Prb: {}'.format(sen, get_probablity(sen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probablity(sentence):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fans = \"\"\"\n",
    "fans = 昵称  偶像  副词 描述 语气 | 偶像 描述 语气 | 偶像 副词 描述  语气\n",
    "昵称 = 我家 | 俺家 | 你家 | 我 | 俺\n",
    "偶像 = 杰森 | 弟弟 | 欧巴 | 小李子 | 大表姐 | 闺女\n",
    "副词 = 炒鸡 | 超级 | 也太 | 好 | 贼\n",
    "描述 = 赞 | 可爱 | 优秀 | 好看 | 油腻 | 猥琐 |鸡贼\n",
    "语气 = 了吧 | 啦 | 了 | 呀 | 啊\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "literature = \"\"\"\n",
    "literature = 量词 形容词 的 主语 动作\n",
    "量词 = 一条 | 两只 | 一群 | 两三个\n",
    "形容词 = 调皮 | 聒噪 | 丧心病狂 | 无法无天\n",
    "主语 = 老汉 | 青年 | 鸡仔 | 鸟儿 | 河流\n",
    "动作 = 走来 | 来过 | 走了 | 飞过 | 淌过\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar_str, target): # you code here\n",
    "    sens = []\n",
    "    for sen in [generate(create_grammar(grammar_str), target) for i in range(10)]:\n",
    "        sens.append((sen, get_probablity(sen)))\n",
    "        print('sentence: {} with Prb: {}'.format(sen, get_probablity(sen)))\n",
    "    sens = sorted(sens, key=lambda x: x[1], reverse=True) \n",
    "    return sens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 一群无法无天的鸟儿飞过 with Prb: 1.3774718372119898e-25\n",
      "sentence: 两三个丧心病狂的老汉走了 with Prb: 1.325664854690678e-30\n",
      "sentence: 一条无法无天的青年来过 with Prb: 7.920463063968942e-25\n",
      "sentence: 一条聒噪的老汉飞过 with Prb: 3.1977024792421195e-26\n",
      "sentence: 一群调皮的鸡仔走了 with Prb: 1.084634881110555e-30\n",
      "sentence: 两三个调皮的老汉淌过 with Prb: 1.479047565150757e-32\n",
      "sentence: 两三个丧心病狂的鸟儿来过 with Prb: 2.1645986013331267e-25\n",
      "sentence: 一群无法无天的河流走来 with Prb: 3.788047552332972e-25\n",
      "sentence: 两只聒噪的河流走了 with Prb: 3.446728622195763e-29\n",
      "sentence: 一条调皮的鸟儿飞过 with Prb: 1.7710352192725587e-25\n",
      "('一条无法无天的青年来过', 7.920463063968942e-25)\n"
     ]
    }
   ],
   "source": [
    "print(generate_best(literature, 'literature'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 闺女也太猥琐了吧 with Prb: 1.4627147386983098e-25\n",
      "sentence: 小李子好好看了吧 with Prb: 1.5269619683454211e-21\n",
      "sentence: 杰森超级好看啦 with Prb: 5.7986958425169105e-18\n",
      "sentence: 小李子好优秀呀 with Prb: 1.9973341639573854e-24\n",
      "sentence: 俺欧巴好优秀啦 with Prb: 1.1045134938127448e-20\n",
      "sentence: 俺家弟弟超级可爱啊 with Prb: 6.966071862472064e-24\n",
      "sentence: 欧巴优秀了吧 with Prb: 2.702081811263499e-16\n",
      "sentence: 弟弟鸡贼啊 with Prb: 4.959607986402306e-14\n",
      "sentence: 俺家大表姐炒鸡猥琐呀 with Prb: 9.860317101005045e-33\n",
      "sentence: 我家欧巴炒鸡油腻啊 with Prb: 3.286772367001682e-33\n",
      "('弟弟鸡贼啊', 4.959607986402306e-14)\n"
     ]
    }
   ],
   "source": [
    "print(generate_best(fans, 'fans'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 今天哥仨去打打牌 with Prb: 2.4597711378785535e-27\n",
      "sentence: 今儿个哥儿几个一块儿喝喝酒 with Prb: 5.477953945002803e-34\n",
      "sentence: 今天哥仨一块儿唱唱歌 with Prb: 1.6433861835008408e-33\n",
      "sentence: 改天咱哥俩去唱唱歌 with Prb: 4.9301585505025234e-33\n",
      "sentence: 今儿个哥儿几个一块儿唱唱歌 with Prb: 1.6433861835008408e-33\n",
      "sentence: 明天咱俩一块儿聊会儿天 with Prb: 5.477953945002803e-34\n",
      "sentence: 今天大伙儿去打打牌 with Prb: 1.1045134938127448e-20\n",
      "sentence: 今儿个哥儿几个一块儿打打牌 with Prb: 2.4597711378785535e-27\n",
      "sentence: 赶明儿哥儿几个去唱唱歌 with Prb: 4.9301585505025234e-33\n",
      "sentence: 今晚咱哥俩去唱唱歌 with Prb: 4.9301585505025234e-33\n",
      "('今天大伙儿去打打牌', 1.1045134938127448e-20)\n"
     ]
    }
   ],
   "source": [
    "print(generate_best(inviting, 'inviting'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否使用 lambda 语法进行排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:1. 语法要预先定义，但语法又难以穷举；\n",
    "2.依赖于使用的语料库，用豆瓣评分训练的模型去验证保险问答数据没有效果；\n",
    "3. 句子的生成概率都较小，概率为10^-20的句子和概率为10^-30其实差别不大。\n",
    "提升的话，听说过一些概率生成模型，先好好学习吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**评阅点**: 是否提出了比较实际的问题，例如OOV问题，例如数据量，例如变成 3-gram问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
